
@article{anselin_thirty_2010,
	title = {Thirty years of spatial econometrics},
	volume = {89},
	issn = {1435-5957},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1435-5957.2010.00279.x/abstract},
	doi = {10.1111/j.1435-5957.2010.00279.x},
	abstract = {Abstract
In this paper, I give a personal view on the development of the field of spatial econometrics during the past 30 years. I argue that it has moved from the margins to the mainstream of applied econometrics and social science methodology. I distinguish three broad phases in the development, which I refer to as preconditions, take off and maturity. For each of these phases I describe the main methodological focus and list major contributions. I conclude with some speculations about future directions.
Resumen
En este art{\'i}culo, expongo mi opini{\'o}n personal sobre el avance en el campo de la econometr{\'i}a espacial durante los {\'u}ltimos 30 a{\~n}os. Mi argumento es que ha pasado de estar en la periferia de la econometr{\'i}a espacial y la metodolog{\'i}a de ciencias sociales a ser algo corriente. Hago la distinci{\'o}n entre tres fases principales en el avance, a las que denomino precondiciones, arranque y madurez. Para cada una de estas fases describo el objetivo metodol{\'o}gico principal y proporciono un listado con las contribuciones principales. Concluyo con especulaciones sobre posibles direcciones en el futuro.},
	language = {en},
	number = {1},
	urldate = {2016-08-24},
	journal = {Papers in Regional Science},
	author = {Anselin, Luc},
	month = mar,
	year = {2010},
	keywords = {B23, C31, R15, regional modelling, spatial analysis, Spatial econometrics},
	pages = {3--25},
	file = {Snapshot:/Users/Justin/Zotero/storage/JQC2VMHT/abstract.html:text/html;Snapshot:/Users/Justin/Zotero/storage/WKTQWVJX/abstract.html:text/html}
}

@article{anderson_multiple_2008,
	title = {Multiple {Inference} and {Gender} {Differences} in the {Effects} of {Early} {Intervention}: {A} {Reevaluation} of the {Abecedarian}, {Perry} {Preschool}, and {Early} {Training} {Projects}},
	volume = {103},
	issn = {0162-1459},
	shorttitle = {Multiple {Inference} and {Gender} {Differences} in the {Effects} of {Early} {Intervention}},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214508000000841},
	doi = {10.1198/016214508000000841},
	abstract = {The view that the returns to educational investments are highest for early childhood interventions is widely held and stems primarily from several influential randomized trials{\textemdash}Abecedarian, Perry, and the Early Training Project{\textemdash}that point to super-normal returns to early interventions. This article presents a de novo analysis of these experiments, focusing on two core issues that have received limited attention in previous analyses: treatment effect heterogeneity by gender and overrejection of the null hypothesis due to multiple inference. To address the latter issue, a statistical framework that combines summary index tests with familywise error rate and false discovery rate corrections is implemented. The first technique reduces the number of tests conducted; the latter two techniques adjust the p values for multiple inference. The primary finding of the reanalysis is that girls garnered substantial short- and long-term benefits from the interventions, but there were no significant long-term benefits for boys. These conclusions, which have appeared ambiguous when using {\textquotedblleft}naive{\textquotedblright} estimators that fail to adjust for multiple testing, contribute to a growing literature on the emerging female{\textendash}male academic achievement gap. They also demonstrate that in complex studies where multiple questions are asked of the same data set, it can be important to declare the family of tests under consideration and to either consolidate measures or report adjusted and unadjusted p values.},
	number = {484},
	urldate = {2013-05-31},
	journal = {Journal of the American Statistical Association},
	author = {Anderson, Michael L.},
	year = {2008},
	pages = {1481--1495},
	file = {Anderson 2008.pdf:/Users/Justin/Zotero/storage/QSE8F3H7/Anderson 2008.pdf:application/pdf;Anderson 2008.pdf:/Users/Justin/Zotero/storage/GFNC6G4P/Anderson 2008.pdf:application/pdf;Anderson 2008.pdf:/Users/Justin/Zotero/storage/6UZAGDPC/Anderson 2008.pdf:application/pdf;Anderson 2008.pdf:/Users/Justin/Zotero/storage/RIN3846Z/Anderson 2008.pdf:application/pdf}
}

@article{banerjee_multifaceted_2015,
	title = {A multifaceted program causes lasting progress for the very poor: {Evidence} from six countries},
	volume = {348},
	shorttitle = {A multifaceted program causes lasting progress for the very poor},
	url = {http://science.sciencemag.org/content/348/6236/1260799.short},
	number = {6236},
	urldate = {2017-04-27},
	journal = {Science},
	author = {Banerjee, Abhijit and Duflo, Esther and Goldberg, Nathanael and Karlan, Dean and Osei, Robert and Parient{\'e}, William and Shapiro, Jeremy and Thuysbaert, Bram and Udry, Christopher},
	year = {2015},
	pages = {1260799},
	file = {[PDF] mit.edu:/Users/Justin/Zotero/storage/E7BASUKR/Banerjee et al. - 2015 - A multifaceted program causes lasting progress for.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/AK5KAWKW/1260799.html:text/html}
}

@article{lee_training_2009,
	title = {Training, wages, and sample selection: {Estimating} sharp bounds on treatment effects},
	volume = {76},
	number = {3},
	journal = {The Review of Economic Studies},
	author = {Lee, David S.},
	year = {2009},
	pages = {1071--1102}
}

@article{tibshirani_regression_1996,
	title = {Regression shrinkage and selection via the lasso},
	url = {http://www.jstor.org/stable/2346178},
	urldate = {2016-02-03},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Tibshirani, Robert},
	year = {1996},
	pages = {267--288},
	file = {[PDF] from yorku.ca:/Users/Justin/Zotero/storage/X3F3TW7E/Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/NBWTEXU7/2346178.html:text/html}
}

@article{mckenzie_beyond_2012,
	title = {Beyond baseline and follow-up: {The} case for more {T} in experiments},
	volume = {99},
	issn = {0304-3878},
	shorttitle = {Beyond baseline and follow-up},
	url = {http://www.sciencedirect.com/science/article/pii/S030438781200003X},
	doi = {10.1016/j.jdeveco.2012.01.002},
	abstract = {The vast majority of randomized experiments in economics rely on a single baseline and single follow-up survey. While such a design is suitable for study of highly autocorrelated and relatively precisely measured outcomes in the health and education domains, it is unlikely to be optimal for measuring noisy and relatively less autocorrelated outcomes such as business profits, and household incomes and expenditures. Taking multiple measurements of such outcomes at relatively short intervals allows one to average out noise, increasing power. When the outcomes have low autocorrelation and budget is limited, it can make sense to do no baseline at all. Moreover, I show how for such outcomes, more power can be achieved with multiple follow-ups than allocating the same total sample size over a single follow-up and baseline. I also highlight the large gains in power from ANCOVA analysis rather than difference-in-differences analysis when autocorrelations are low.},
	number = {2},
	urldate = {2014-10-28},
	journal = {Journal of Development Economics},
	author = {McKenzie, David},
	month = nov,
	year = {2012},
	keywords = {Program evaluation, Multiple measurements, Randomized experiments},
	pages = {210--221},
	file = {ScienceDirect Full Text PDF:/Users/Justin/Zotero/storage/8AUXDPNH/McKenzie - 2012 - Beyond baseline and follow-up The case for more T.pdf:application/pdf;ScienceDirect Snapshot:/Users/Justin/Zotero/storage/D2UQTQP3/S030438781200003X.html:text/html}
}

@article{zellner_efficient_1962,
	title = {An {Efficient} {Method} of {Estimating} {Seemingly} {Unrelated} {Regressions} and {Tests} for {Aggregation} {Bias}},
	volume = {57},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1962.10480664},
	doi = {10.1080/01621459.1962.10480664},
	abstract = {In this paper a method of estimating the parameters of a set of regression equations is reported which involves application of Aitken's generalized least-squares [1] to the whole system of equations. Under conditions generally encountered in practice, it is found that the regression coefficient estimators so obtained are at least asymptotically more efficient than those obtained by an equation-by-equation application of least squares. This gain in efficiency can be quite large if {\textquotedblleft}independent{\textquotedblright} variables in different equations are not highly correlated and if disturbance terms in different equations are highly correlated. Further, tests of the hypothesis that all regression equation coefficient vectors are equal, based on {\textquotedblleft}micro{\textquotedblright} and {\textquotedblleft}macro{\textquotedblright} data, are described. If this hypothesis is accepted, there will be no aggregation bias. Finally, the estimation procedure and the {\textquotedblleft}micro-test{\textquotedblright} for aggregation bias are applied in the analysis of annual investment data, 1935{\textendash}1954, for two firms.},
	number = {298},
	urldate = {2014-11-18},
	journal = {Journal of the American Statistical Association},
	author = {Zellner, Arnold},
	month = jun,
	year = {1962},
	pages = {348--368},
	file = {Full Text PDF:/Users/Justin/Zotero/storage/MVW6FPWM/Zellner - 1962 - An Efficient Method of Estimating Seemingly Unrela.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/A87X8WXF/01621459.1962.html:text/html}
}

@article{benjamini_adaptive_2006,
	title = {Adaptive {Linear} {Step}-up {Procedures} {That} {Control} the {False} {Discovery} {Rate}},
	url = {http://www.jstor.org/stable/20441303},
	urldate = {2016-07-06},
	journal = {Biometrika},
	author = {Benjamini, Yoav and Krieger, Abba M. and Yekutieli, Daniel},
	year = {2006},
	pages = {491--507},
	file = {Snapshot:/Users/Justin/Zotero/storage/64UUS57I/20441303.html:text/html}
}

@article{haushofer_short-term_2016,
	title = {The {Short}-{Term} {Impact} of {Unconditional} {Cash} {Transfers} to the {Poor}: {Experimental} {Evidence} from {Kenya}},
	issn = {0033-5533, 1531-4650},
	shorttitle = {The {Short}-{Term} {Impact} of {Unconditional} {Cash} {Transfers} to the {Poor}},
	url = {http://qje.oxfordjournals.org/content/early/2016/07/14/qje.qjw025},
	doi = {10.1093/qje/qjw025},
	abstract = {We use a randomized controlled trial to study the response of poor households in rural Kenya to large, unconditional cash transfers from the NGO GiveDirectly. The transfers differ from other programs in that they are explicitly unconditional, large, and concentrated in time. We randomized at both the village and household levels; further, within the treatment group, we randomized recipient gender (wife vs. husband), transfer timing (lump-sum transfer vs. monthly installments), and transfer magnitude (USD 404 PPP vs. USD 1,525 PPP). We find a strong consumption response to transfers, with an increase in household monthly consumption from USD 158 PPP to USD 193 PPP nine months after the transfer began. Transfer recipients experience large increases in psychological wellbeing. We find no overall effect on levels of the stress hormone cortisol, although there are differences across some subgroups. Monthly transfers are more likely than lump-sum transfers to improve food security, while lump-sum transfers are more likely to be spent on durables, suggesting that households face savings and credit constraints. Together, these results suggest that unconditional cash transfers have significant impacts on economic outcomes and psychological wellbeing.},
	language = {en},
	urldate = {2017-01-16},
	journal = {The Quarterly Journal of Economics},
	author = {Haushofer, Johannes and Shapiro, Jeremy},
	month = jul,
	year = {2016},
	keywords = {C93, O12, D12, D13, D14},
	pages = {qjw025},
	file = {Snapshot:/Users/Justin/Zotero/storage/AUTMJN42/qje.qjw025.html:text/html}
}

@article{jorgenson_capital_1963,
	title = {Capital theory and investment behavior},
	volume = {53},
	url = {http://www.jstor.org/stable/1823868},
	number = {2},
	urldate = {2016-12-13},
	journal = {The American Economic Review},
	author = {Jorgenson, Dale W.},
	year = {1963},
	pages = {247--259},
	file = {[PDF] researchgate.net:/Users/Justin/Zotero/storage/NQC6SV3A/Jorgenson - 1963 - Capital theory and investment behavior.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/HD69GHP6/1823868.html:text/html}
}

@book{office_consumer_2004,
	title = {Consumer price index manual: theory and practice},
	shorttitle = {Consumer price index manual},
	publisher = {International Monetary Fund},
	author = {Office, International Labour and Turvey, Ralph},
	year = {2004}
}

@article{amendola_durable_2014,
	title = {Durable goods and poverty measurement},
	url = {http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2524159},
	number = {7105},
	urldate = {2016-12-13},
	journal = {World Bank Policy Research Working Paper},
	author = {Amendola, Nicola and Vecchi, Giovanni},
	year = {2014},
	file = {[PDF] torvergata.it:/Users/Justin/Zotero/storage/GSBKTCX8/Amendola and Vecchi - 2014 - Durable goods and poverty measurement.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/UNCSSIZ9/papers.html:text/html}
}

@book{deaton_guidelines_2002,
	title = {Guidelines for constructing consumption aggregates for welfare analysis},
	volume = {135},
	url = {https://books.google.com/books?hl=en&lr=&id=wpZgrh650wgC&oi=fnd&pg=PR7&dq=deaton+zaidi+2002&ots=_zv_nD1ORA&sig=9YWHrU18DhEs_EsW_ZxNGZ-dtpc},
	urldate = {2016-12-13},
	publisher = {World Bank Publications},
	author = {Deaton, Angus and Zaidi, Salman},
	year = {2002},
	file = {[HTML] google.com:/Users/Justin/Zotero/storage/TDDBNQDF/books.html:text/html}
}

@article{tibshirani_regression_1996-1,
	title = {Regression {Shrinkage} and {Selection} via the {Lasso}},
	volume = {58},
	issn = {0035-9246},
	url = {http://www.jstor.org/stable/2346178},
	abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
	number = {1},
	urldate = {2016-12-05},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Tibshirani, Robert},
	year = {1996},
	pages = {267--288}
}

@article{krstajic_cross-validation_2014,
	title = {Cross-validation pitfalls when selecting and assessing regression and classification models},
	volume = {6},
	issn = {1758-2946},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3994246/},
	doi = {10.1186/1758-2946-6-10},
	abstract = {Background
We address the problem of selecting and assessing classification and regression models using cross-validation. Current state-of-the-art methods can yield models with high variance, rendering them unsuitable for a number of practical applications including QSAR. In this paper we describe and evaluate best practices which improve reliability and increase confidence in selected models. A key operational component of the proposed methods is cloud computing which enables routine use of previously infeasible approaches.

Methods
We describe in detail an algorithm for repeated grid-search V-fold cross-validation for parameter tuning in classification and regression, and we define a repeated nested cross-validation algorithm for model assessment. As regards variable selection and parameter tuning we define two algorithms (repeated grid-search cross-validation and double cross-validation), and provide arguments for using the repeated grid-search in the general case.

Results
We show results of our algorithms on seven QSAR datasets. The variation of the prediction performance, which is the result of choosing different splits of the dataset in V-fold cross-validation, needs to be taken into account when selecting and assessing classification and regression models.

Conclusions
We demonstrate the importance of repeating cross-validation when selecting an optimal model, as well as the importance of repeating nested cross-validation when assessing a prediction error.},
	urldate = {2016-11-28},
	journal = {Journal of Cheminformatics},
	author = {Krstajic, Damjan and Buturovic, Ljubomir J and Leahy, David E and Thomas, Simon},
	month = mar,
	year = {2014},
	pmid = {24678909},
	pmcid = {PMC3994246},
	pages = {10},
	file = {PubMed Central Full Text PDF:/Users/Justin/Zotero/storage/KJPT7T7T/Krstajic et al. - 2014 - Cross-validation pitfalls when selecting and asses.pdf:application/pdf}
}

@article{romano_inference_2008,
	series = {Special {Issue} in {Honor} of {Theodore} {Wilbur} {Anderson}, {Jr}. on the {Occasion} of his 90th {Birthday}},
	title = {Inference for identifiable parameters in partially identified econometric models},
	volume = {138},
	issn = {0378-3758},
	url = {http://www.sciencedirect.com/science/article/pii/S0378375808000694},
	doi = {10.1016/j.jspi.2008.03.015},
	abstract = {This paper considers the problem of inference for partially identified econometric models. The class of models studied are defined by a population objective function Q ( $\theta$ , P ) for $\theta$ ? $\Theta$ . The second argument indicates the dependence of the objective function on P , the distribution of the observed data. Unlike the classical extremum estimation framework, it is not assumed that Q ( $\theta$ , P ) has a unique minimizer in the parameter space $\Theta$ . The goal may be either to draw inferences about some unknown point in the set of minimizers of the population objective function or to draw inferences about the set of minimizers itself. In this paper, the object of interest is some unknown point $\theta$ ? $\Theta$ 0 ( P ) , where $\Theta$ 0 ( P ) = arg min $\theta$ ? $\Theta$ Q ( $\theta$ , P ) , and so we seek random sets that contain each $\theta$ ? $\Theta$ 0 ( P ) with at least some prespecified probability asymptotically. We also consider situations where the object of interest is the image of some point $\theta$ ? $\Theta$ 0 ( P ) under a known function. Computationally intensive, yet feasible procedures for constructing random sets satisfying the desired coverage property under weak assumptions are provided. We also provide conditions under which the confidence regions are uniformly consistent in level.},
	number = {9},
	urldate = {2016-11-18},
	journal = {Journal of Statistical Planning and Inference},
	author = {Romano, Joseph P. and Shaikh, Azeem M.},
	month = sep,
	year = {2008},
	keywords = {interval regression, Confidence region, Extremum estimation, Identifiable parameter, Identified set, Incomplete model, Moment inequalities, Partially identified model, Subsampling, Uniform coverage},
	pages = {2786--2807},
	file = {ScienceDirect Snapshot:/Users/Justin/Zotero/storage/FZ6D79CG/S0378375808000694.html:text/html}
}

@article{blumenstock_predicting_2015,
	title = {Predicting poverty and wealth from mobile phone metadata},
	volume = {350},
	url = {http://science.sciencemag.org/content/350/6264/1073.short},
	number = {6264},
	urldate = {2016-11-05},
	journal = {Science},
	author = {Blumenstock, Joshua and Cadamuro, Gabriel and On, Robert},
	year = {2015},
	pages = {1073--1076},
	file = {[PDF] from unipi.it:/Users/Justin/Zotero/storage/FXJVF5FR/Blumenstock et al. - 2015 - Predicting poverty and wealth from mobile phone me.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/A8N55WFA/1073.html:text/html}
}

@techreport{blair_predicting_2015,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Predicting {Local} {Violence}},
	url = {https://papers.ssrn.com/abstract=2497153},
	abstract = {This paper tests the feasibility of local-level violence forecasting. We apply standard prediction models to new data from 242 Liberian communities to investigate whether it is to possible to predict outbreaks of local violence with sensitivity and accuracy, even with limited data. We first trained our models to predict communal, extrajudicial, and criminal violence in 2010 using 2008 risk factors. We then made forecasts of violence in 2012, before collecting data. Our model predicted up to 88\% of actual 2012 violence. This came at the cost of many false positives, for overall accuracy of 33 to 50\%. Policy-wise, states and peacekeepers could use such predictions to prevent and respond to violence. The models also generated new stylized facts for theory to explain. In this case, ethnic cleavages and power-sharing predicted violence, while economic variables typically did not. We illustrate how forecasting can be widely more applied to micro-level conflict data.},
	number = {ID 2497153},
	urldate = {2016-11-05},
	institution = {Social Science Research Network},
	author = {Blair, Robert A. and Blattman, Christopher and Hartman, Alexandra},
	month = apr,
	year = {2015},
	keywords = {Violence, Crime, Liberia, early warning, ethnic politics, fights, forecasting, prediction, riots},
	file = {Snapshot:/Users/Justin/Zotero/storage/P3IEUPQP/papers.html:text/html}
}

@techreport{heckman_general_1998,
	type = {Working {Paper}},
	title = {General {Equilibrium} {Treatment} {Effects}: {A} {Study} of {Tuition} {Policy}},
	shorttitle = {General {Equilibrium} {Treatment} {Effects}},
	url = {http://www.nber.org/papers/w6426},
	abstract = {This paper defines and estimates general equilibrium treatment effects. The conventional approach in the literature on treatment effects ignores interactions among individuals induced by the policy interventions being studied. Focusing on the impact of tuition policy, and using estimates from our dynamic overlapping generations general equilibrium model of capital and human capital formation, we find that general equilibrium impacts of tuition on college enrollment are an order of magnitude smaller than those reported in the literature on microeconomic treatment effects. The assumptions used to justify the LATE parameter in a partial equilibrium setting do not hold in a general equilibrium setting. Policy changes induce two way flows. We extend the LATE concept to a general equilibrium setting. We present a more comprehensive evaluation to program evaluation by considering both the tax and benefit consequences of the program being evaluated and placing the analysis in a market setting.},
	number = {6426},
	urldate = {2016-09-01},
	institution = {National Bureau of Economic Research},
	author = {Heckman, James J. and Lochner, Lance and Taber, Christopher},
	month = feb,
	year = {1998},
	file = {NBER Full Text PDF:/Users/Justin/Zotero/storage/E2XS26RK/Heckman et al. - 1998 - General Equilibrium Treatment Effects A Study of .pdf:application/pdf}
}

@article{redding_quantitative_2016,
	title = {Quantitative {Spatial} {Economics}},
	url = {http://www.princeton.edu/~reddings/papers/ARQSM-16July2016.pdf},
	urldate = {2016-08-31},
	author = {Redding, Stephen J. and Rossi-Hansberg, Esteban},
	year = {2016},
	file = {[PDF] from princeton.edu:/Users/Justin/Zotero/storage/IHC3AHWW/Redding and Rossi-Hansberg - 2016 - Quantitative Spatial Economics.pdf:application/pdf}
}

@article{gibbons_mostly_2012,
	title = {Mostly {Pointless} {Spatial} {Econometrics}?*},
	volume = {52},
	issn = {1467-9787},
	shorttitle = {Mostly {Pointless} {Spatial} {Econometrics}?},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9787.2012.00760.x/abstract},
	doi = {10.1111/j.1467-9787.2012.00760.x},
	abstract = {ABSTRACT We argue that identification problems bedevil applied spatial economic research. Spatial econometrics usually solves these problems by deriving estimators assuming that functional forms are known and by using model comparison techniques to let the data choose between competing specifications. We argue that in many situations of interest this achieves, at best, only very weak identification. Worse, in many cases, such an approach will be uninformative about the causal economic processes at work, rendering much applied spatial econometric research {\textquotedblleft}pointless,{\textquotedblright} unless the main aim is description of the data. We advocate an alternative approach based on the {\textquotedblleft}experimentalist paradigm{\textquotedblright} which puts issues of identification and causality at center stage.},
	language = {en},
	number = {2},
	urldate = {2016-08-30},
	journal = {Journal of Regional Science},
	author = {Gibbons, Stephen and Overman, Henry G.},
	month = may,
	year = {2012},
	pages = {172--191},
	file = {Full Text PDF:/Users/Justin/Zotero/storage/PWNW9SQW/Gibbons and Overman - 2012 - Mostly Pointless Spatial Econometrics.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/ZHXEVC4S/abstract.html:text/html}
}

@article{ahrens_two-step_2015,
	title = {Two-{Step} {Lasso} {Estimation} of the {Spatial} {Weights} {Matrix}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://www.mdpi.com/2225-1146/3/1/128},
	doi = {10.3390/econometrics3010128},
	abstract = {The vast majority of spatial econometric research relies on the assumption that the spatial network structure is known a priori. This study considers a two-step estimation strategy for estimating the n(n-1) interaction effects in a spatial autoregressive panel model where the spatial dimension is potentially large. The identifying assumption is approximate sparsity of the spatial weights matrix. The proposed estimation methodology exploits the Lasso estimator and mimics two-stage least squares (2SLS) to account for endogeneity of the spatial lag. The developed two-step estimator is of more general interest. It may be used in applications where the number of endogenous regressors and the number of instrumental variables is larger than the number of observations. We derive convergence rates for the two-step Lasso estimator. Our Monte Carlo simulation results show that the two-step estimator is consistent and successfully recovers the spatial network structure for reasonable sample size, T.},
	language = {en},
	number = {1},
	urldate = {2016-08-30},
	journal = {Econometrics},
	author = {Ahrens, Achim and Bhattacharjee, Arnab},
	month = mar,
	year = {2015},
	keywords = {endogeneity, lasso, spatial weights matrix, unkown W},
	pages = {128--155},
	file = {Full Text PDF:/Users/Justin/Zotero/storage/5CPMKBF5/Ahrens and Bhattacharjee - 2015 - Two-Step Lasso Estimation of the Spatial Weights M.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/P9NFDB58/htm.html:text/html}
}

@inproceedings{vega_spatial_2013,
	title = {On spatial econometric models, spillover effects, and {W}},
	url = {http://www-sre.wu.ac.at/ersa/ersaconfs/ersa13/ERSA2013_paper_00222.pdf},
	urldate = {2016-08-30},
	author = {Vega, Solmaria Halleck and Elhorst, J. Paul},
	year = {2013},
	file = {[PDF] wu.ac.at:/Users/Justin/Zotero/storage/3GZG4QQA/Vega and Elhorst - 2013 - On spatial econometric models, spillover effects, .pdf:application/pdf}
}

@techreport{lesage_what_2014,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {What {Regional} {Scientists} {Need} to {Know} {About} {Spatial} {Econometrics}},
	url = {http://papers.ssrn.com/abstract=2420725},
	abstract = {Regional scientists frequently work with regression relationships involving sample data that is spatial in nature. For example, hedonic house-price regressions relate selling prices of houses located at points in space to characteristics of the homes as well as neighborhood characteristics. Migration, commodity, and transportation flow models relate the size flows between origin and destination regions to the distance between origin and destination as well as characteristics of both origin and destination regions. Regional growth regressions relate growth rates of a region to past period own- and nearby-region resource inputs used in production.Spatial data typically violates the assumption that each observation is independent of other observations made by ordinary regression methods. This has econometric implications for the quality of estimates and inferences drawn from non-spatial regression models. Alternative methods for producing point estimates and drawing inferences for relationships involving spatial data samples is the broad topic covered by spatial econometrics. Like any sub-discipline, spatial econometrics has its quirks, many of which reflect influential past literature that has gained attention in both theoretical and applied work.This article asks the question -- what should regional scientists who wish to use regression relationships involving spatial data in an effort to shed light on questions of interest in regional science know about spatial econometric methods?},
	number = {ID 2420725},
	urldate = {2016-08-26},
	institution = {Social Science Research Network},
	author = {LeSage, James P.},
	month = jan,
	year = {2014},
	keywords = {local versus global spillovers, Monte Carlo studies},
	file = {Snapshot:/Users/Justin/Zotero/storage/6QNEDXPK/Papers.html:text/html}
}

@article{lesage_biggest_2010,
	title = {The biggest myth in spatial econometrics},
	url = {http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1725503},
	urldate = {2016-08-26},
	journal = {Available at SSRN 1725503},
	author = {LeSage, James P. and Pace, R. Kelley},
	year = {2010},
	file = {Snapshot:/Users/Justin/Zotero/storage/ZXZJXWQ5/papers.html:text/html}
}

@article{kopczewska_strategy_2015,
	title = {Strategy of {Spatial} {Panel} {Estimation}: {Spatial} {Spillovers} {Between} {Taxation} and {Economic} {Growth}},
	issn = {1874-463X, 1874-4621},
	shorttitle = {Strategy of {Spatial} {Panel} {Estimation}},
	url = {http://link.springer.com/article/10.1007/s12061-015-9170-2},
	doi = {10.1007/s12061-015-9170-2},
	abstract = {Spatial panels are a powerful econometric tool for the estimation of space-dependent cross-sectional time-series models of economic phenomena. A plethora of parameters and possible specifications require a systematic approach to estimation. This paper presents a strategy of estimation to be considered in applied research on economic policy, including the concept of spatial spillovers and its local and global effects, direct and indirect impacts, as well as the role of different spatial weighting schemes. The paper presents fiscal factors affecting GDP between the years 2002{\textendash}2015 in a number of European economies.},
	language = {en},
	urldate = {2016-08-26},
	journal = {Applied Spatial Analysis and Policy},
	author = {Kopczewska, K. and Kud{\l }a, J. and Walczyk, K.},
	month = oct,
	year = {2015},
	pages = {1--26},
	file = {Full Text PDF:/Users/Justin/Zotero/storage/9VEIJ6AM/Kopczewska et al. - 2015 - Strategy of Spatial Panel Estimation Spatial Spil.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/IVHEUVGG/s12061-015-9170-2.html:text/html}
}

@book{banerjee_hierarchical_2014,
	title = {Hierarchical {Modeling} and {Analysis} for {Spatial} {Data}, {Second} {Edition}},
	isbn = {978-1-4398-1918-0},
	abstract = {Keep Up to Date with the Evolving Landscape of Space and Space-Time Data Analysis and Modeling Since the publication of the first edition, the statistical landscape has substantially changed for analyzing space and space-time data. More than twice the size of its predecessor, Hierarchical Modeling and Analysis for Spatial Data, Second Edition reflects the major growth in spatial statistics as both a research area and an area of application. New to the Second Edition   New chapter on spatial point patterns developed primarily from a modeling perspective New chapter on big data that shows how the predictive process handles reasonably large datasets New chapter on spatial and spatiotemporal gradient modeling that incorporates recent developments in spatial boundary analysis and wombling New chapter on the theoretical aspects of geostatistical (point-referenced) modeling  Greatly expanded chapters on methods for multivariate and spatiotemporal modeling New special topics sections on data fusion/assimilation and spatial analysis for data on extremes Double the number of exercises  Many more color figures integrated throughout the text Updated computational aspects, including the latest version of WinBUGS, the new flexible spBayes software, and assorted R packages  The Only Comprehensive Treatment of the Theory, Methods, and Software This second edition continues to provide a complete treatment of the theory, methods, and application of hierarchical modeling for spatial and spatiotemporal data. It tackles current challenges in handling this type of data, with increased emphasis on observational data, big data, and the upsurge of associated software tools. The authors also explore important application domains, including environmental science, forestry, public health, and real estate.},
	language = {en},
	publisher = {CRC Press},
	author = {Banerjee, Sudipto and Carlin, Bradley P. and Gelfand, Alan E.},
	month = sep,
	year = {2014},
	note = {Google-Books-ID: WVHRBQAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / General, Science / Earth Sciences / Geology, Science / Life Sciences / Biology}
}

@article{lesage_introduction_0,
	title = {An {Introduction} to {Spatial} {Econometrics}},
	issn = {0154-3229},
	url = {http://www.cairn.info/resume.php?ID_ARTICLE=REI_123_0019},
	language = {fr},
	number = {123},
	urldate = {2016-08-24},
	journal = {Revue d'{\'e}conomie industrielle},
	author = {Lesage, James P.},
	year = {0},
	keywords = {d{\'e}pendance spatiale, {\'e}conom{\'e}trie spatiale, processus spatial autor{\'e}gressif},
	pages = {19--44},
	file = {James_LeSage_Robert_Kelley_Pace-Introduction_to_Spatial_Econometrics_Statistics___A_Series_of_Textbooks_and_Monographs-Chapman_and_Hall_CRC2009.pdf:/Users/Justin/Zotero/storage/6ZSZ5R8J/James_LeSage_Robert_Kelley_Pace-Introduction_to_Spatial_Econometrics_Statistics___A_Series_of_Textbooks_and_Monographs-Chapman_and_Hall_CRC2009.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/ZI9GRG8E/resume.html:text/html}
}

@book{griffith_non-standard_2011,
	title = {Non-standard {Spatial} {Statistics} and {Spatial} {Econometrics}},
	isbn = {978-3-642-16043-1},
	abstract = {Despite spatial statistics and spatial econometrics both being recent sprouts of the general tree "spatial analysis with measurement"{\textemdash}some may remember the debate after WWII about "theory without measurement" versus "measurement without theory"{\textemdash}several general themes have emerged in the pertaining literature. But exploring selected other fields of possible interest is tantalizing, and this is what the authors intend to report here, hoping that they will suscitate interest in the methodologies exposed and possible further applications of these methodologies. The authors hope that reactions about their publication will ensue, and they would be grateful to reader(s) motivated by some of the research efforts exposed hereafter letting them know about these experiences.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Griffith, Daniel A. and Paelinck, Jean H. Paul},
	month = jan,
	year = {2011},
	note = {Google-Books-ID: WK439dKDxDIC},
	keywords = {Business \& Economics / General, Business \& Economics / Management Science, Science / Earth Sciences / Geography, Social Science / Emigration \& Immigration}
}

@article{rosen_wage-based_1979,
	title = {Wage-based indexes of urban quality of life},
	volume = {3},
	journal = {Current issues in urban economics},
	author = {Rosen, Sherwin},
	year = {1979}
}

@article{roback_wages_1982,
	title = {Wages, {Rents}, and the {Quality} of {Life}},
	volume = {90},
	issn = {0022-3808},
	url = {http://www.jstor.org/stable/1830947},
	abstract = {This study focuses on the role of wages and rents in allocating workers to locations with various quantities of amenities. The theory demonstrates that if the amenity is also productive, then the sign of the wage gradient is unclear while the rent gradient is positive. The theory is extended to include the housing market and nontraded goods. These extensions require little modification of the conclusion. The empirical work on wages shows that the regional wage differences can be explained largely by these local attributes. With the use of site price data, implicit prices are estimated and quality of life rankings for the cities are computed.},
	number = {6},
	urldate = {2016-08-24},
	journal = {Journal of Political Economy},
	author = {Roback, Jennifer},
	year = {1982},
	pages = {1257--1278}
}

@incollection{enrico_chapter_2011,
	title = {Chapter 14 - {Local} {Labor} {Markets}*},
	volume = {4, Part B},
	url = {http://www.sciencedirect.com/science/article/pii/S0169721811024129},
	abstract = {I examine the causes and the consequences of differences in labor market outcomes across local labor markets within a country. The focus is on a long-run general equilibrium setting, where workers and firms are free to move across localities and local prices adjust to maintain the spatial equilibrium. In particular, I develop a tractable general equilibrium framework of local labor markets with heterogenous labor. This framework is useful in thinking about differences in labor market outcomes of different skill groups across locations. It clarifies how, in spatial equilibrium, localized shocks to a part of the labor market propagate to the rest of the economy through changes in employment, wages and local prices and how this diffusion affects workers{\textquoteright} welfare. Using this framework, I address three related questions. First, I analyze the welfare consequences of productivity differences across local labor markets. I seek to understand what happens to the wage, employment and utility of workers with different skill levels when a local economy experiences a shift in the productivity of a group of workers. Second, I analyze the causes of productivity differences across local labor markets. To a large extent, productivity differences within a country are unlikely to be exogenous. I review the theoretical and empirical literature on agglomeration economies, with a particular focus on studies that are relevant for labor economists. Finally, I discuss the implications for policy.},
	urldate = {2016-08-24},
	booktitle = {Handbook of {Labor} {Economics}},
	publisher = {Elsevier},
	author = {Enrico, Moretti},
	editor = {Ashenfelter, David Card {and} Orley},
	year = {2011},
	keywords = {Cities, General equilibrium, Spatial equilibrium, Wage},
	pages = {1237--1313},
	file = {ScienceDirect Snapshot:/Users/Justin/Zotero/storage/TG5U3FQE/S0169721811024129.html:text/html;w15947.pdf:/Users/Justin/Zotero/storage/2JQN7A7J/w15947.pdf:application/pdf}
}

@techreport{kline_local_2013,
	title = {Local economic development, agglomeration economies, and the big push: 100 years of evidence from the {Tennessee} {Valley} {Authority}},
	shorttitle = {Local economic development, agglomeration economies, and the big push},
	url = {http://www.nber.org/papers/w19293},
	urldate = {2016-08-24},
	institution = {National Bureau of Economic Research},
	author = {Kline, Patrick M. and Moretti, Enrico},
	year = {2013},
	file = {[HTML] from oxfordjournals.org:/Users/Justin/Zotero/storage/FJB72R9J/275.html:text/html;Snapshot:/Users/Justin/Zotero/storage/Z4MXHWXA/w19293.html:text/html}
}

@article{moretti_local_2013,
	title = {Local multipliers and human capital in the {United} {States} and {Sweden}},
	volume = {22},
	url = {http://icc.oxfordjournals.org/content/22/1/339.short},
	number = {1},
	urldate = {2016-08-24},
	journal = {Industrial and Corporate Change},
	author = {Moretti, Enrico and Thulin, Per},
	year = {2013},
	pages = {339--362},
	file = {[HTML] from oxfordjournals.org:/Users/Justin/Zotero/storage/VSI8R7CT/339.html:text/html;Snapshot:/Users/Justin/Zotero/storage/QWKNEWH7/339.html:text/html}
}

@techreport{kline_people_2013,
	type = {Working {Paper}},
	title = {People, {Places} and {Public} {Policy}: {Some} {Simple} {Welfare} {Economics} of {Local} {Economic} {Development} {Programs}},
	shorttitle = {People, {Places} and {Public} {Policy}},
	url = {http://www.nber.org/papers/w19659},
	abstract = {Most countries exhibit large and persistent geographical differences in wages, income and unemployment rates. A growing class of "place based" policies attempt to address these differences through public investments and subsidies that target disadvantaged neighborhoods, cities or regions. Place based policies have the potential to profoundly affect the location of economic activity, along with the wages, employment, and industry mix of communities. These programs are widespread in the U.S. and throughout the world, but have only recently been studied closely by economists. We consider the following questions: Who benefits from place based interventions? Do the national benefits outweigh the costs? What sorts of interventions are most likely to be effective?To study these questions, we develop a simple spatial equilibrium model designed to characterize the welfare effects of place based policies on the local and the national economy. Using this model, we critically evaluate the economic rationales for place based policies and assess the latest evidence on their effects. We conclude with some lessons for policy and directions for future research.},
	number = {19659},
	urldate = {2016-08-24},
	institution = {National Bureau of Economic Research},
	author = {Kline, Patrick and Moretti, Enrico},
	month = nov,
	year = {2013}
}

@article{glaeser_wealth_2009,
	title = {The {Wealth} of {Cities}: {Agglomeration} {Economies} and {Spatial} {Equilibrium} in the {United} {States}},
	volume = {47},
	shorttitle = {The {Wealth} of {Cities}},
	doi = {10.1257/jel.47.4.983},
	abstract = {Empirical research on cities starts with a spatial equilibrium condition: workers and firms are assumed to be indifferent across space. This condition implies that research on cities is different from research on countries, and that work on places within countries needs to consider population, income, and housing prices simultaneously. Housing supply elasticity will determine whether urban success reveals itself in the form of more people or higher incomes. Urban economists generally accept the existence of agglomeration economies, which exist when productivity rises with density, but estimating the magnitude of those economies is difficult. Some manufacturing firms cluster to reduce the costs of moving goods, but this force no longer appears to be important in driving urban success. Instead, modern cities are far more dependent on the role that density can play in speeding the flow of ideas. Finally, urban economics has some insights to offer related topics such as growth theory, national income accounts, public economics, and housing prices.},
	number = {4},
	journal = {Journal of Economic Literature},
	author = {Glaeser, Edward L. and Gottlieb, Joshua D.},
	month = dec,
	year = {2009},
	pages = {983--1028}
}

@techreport{glaeser_cities_2008,
	type = {{OUP} {Catalogue}},
	title = {Cities, {Agglomeration}, and {Spatial} {Equilibrium}},
	url = {https://ideas.repec.org/b/oxp/obooks/9780199290444.html},
	abstract = {220 million Americans crowd together in the 3\% of the country that is urban. 35 million people live in the vast metropolis of Tokyo, the most productive urban area in the world. The central city of Mumbai alone has 12 million people, and Shanghai almost as many. We choose to live cheek by jowl, in a planet with vast amounts of space. Yet despite all of the land available to us, we choose to live in proximity to cities. Using economics to understand this phenomenon, the urban economist uses the tools of economic theory and empirical data to explain why cities exist and to analyze urban issues such as housing, education, crime, poverty and social interaction. Drawing on the success of his Lindahl lectures, Edward Glaeser provides a rigorous account of his research and unique thinking on cities. Using a series of simple models and economic theory, Glaeser illustrates the primary features of urban economics including the concepts of spatial equilibrium and agglomeration economies. Written for a mathematically inclined audience with an interest in urban economics and cities, the book is written to be accessible to theorists and non-theorists alike and should provide a basis for further empirical work.},
	urldate = {2016-08-24},
	institution = {Oxford University Press},
	author = {Glaeser, Edward L.},
	year = {2008},
	file = {RePEc Snapshot:/Users/Justin/Zotero/storage/SRRGXV3S/9780199290444.html:text/html}
}

@article{athey_recursive_2015,
	title = {Recursive partitioning for heterogeneous causal effects},
	url = {http://arxiv.org/abs/1504.01132},
	urldate = {2016-08-24},
	journal = {arXiv preprint arXiv:1504.01132},
	author = {Athey, Susan and Imbens, Guido},
	year = {2015},
	file = {[PDF] arxiv.org:/Users/Justin/Zotero/storage/C6U6ZWBZ/Athey and Imbens - 2015 - Recursive partitioning for heterogeneous causal ef.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/HZQ6TWQI/1504.html:text/html}
}

@article{athey_machine_2015,
	title = {Machine learning methods for estimating heterogeneous causal effects},
	volume = {1050},
	url = {https://www.researchgate.net/profile/Guido_Imbens/publication/274644919_Machine_Learning_Methods_for_Estimating_Heterogeneous_Causal_Effects/links/553c02250cf2c415bb0b1720.pdf},
	urldate = {2016-08-24},
	journal = {stat},
	author = {Athey, Susan and Imbens, Guido W.},
	year = {2015},
	pages = {5},
	file = {[PDF] researchgate.net:/Users/Justin/Zotero/storage/6BSTFNCP/Athey and Imbens - 2015 - Machine learning methods for estimating heterogene.pdf:application/pdf}
}

@article{bloniarz_lasso_2015,
	title = {Lasso adjustments of treatment effect estimates in randomized experiments},
	url = {http://arxiv.org/abs/1507.03652},
	urldate = {2016-10-20},
	journal = {arXiv preprint arXiv:1507.03652},
	author = {Bloniarz, Adam and Liu, Hanzhong and Zhang, Cun-Hui and Sekhon, Jasjeet and Yu, Bin},
	year = {2015},
	file = {[PDF] arxiv.org:/Users/Justin/Zotero/storage/S4WPUNAB/Bloniarz et al. - 2015 - Lasso adjustments of treatment effect estimates in.pdf:application/pdf;Snapshot:/Users/Justin/Zotero/storage/B4F2PQSA/1507.html:text/html}
}

@article{lin_agnostic_2013,
	title = {Agnostic notes on regression adjustments to experimental data: {Reexamining} {Freedman}{\textquoteright}s critique},
	volume = {7},
	issn = {1932-6157, 1941-7330},
	shorttitle = {Agnostic notes on regression adjustments to experimental data},
	url = {http://projecteuclid.org/euclid.aoas/1365527200},
	doi = {10.1214/12-AOAS583},
	abstract = {Freedman [Adv. in Appl. Math. 40 (2008) 180{\textendash}193; Ann. Appl. Stat. 2 (2008) 176{\textendash}196] critiqued ordinary least squares regression adjustment of estimated treatment effects in randomized experiments, using Neyman{\textquoteright}s model for randomization inference. Contrary to conventional wisdom, he argued that adjustment can lead to worsened asymptotic precision, invalid measures of precision, and small-sample bias. This paper shows that in sufficiently large samples, those problems are either minor or easily fixed. OLS adjustment cannot hurt asymptotic precision when a full set of treatment{\textendash}covariate interactions is included. Asymptotically valid confidence intervals can be constructed with the Huber{\textendash}White sandwich standard error estimator. Checks on the asymptotic approximations are illustrated with data from Angrist, Lang, and Oreopoulos{\textquoteright}s [Am. Econ. J.: Appl. Econ. 1:1 (2009) 136{\textendash}163] evaluation of strategies to improve college students{\textquoteright} achievement. The strongest reasons to support Freedman{\textquoteright}s preference for unadjusted estimates are transparency and the dangers of specification search.},
	language = {EN},
	number = {1},
	urldate = {2016-10-20},
	journal = {The Annals of Applied Statistics},
	author = {Lin, Winston},
	month = mar,
	year = {2013},
	mrnumber = {MR3086420},
	zmnumber = {06171273},
	keywords = {Analysis of covariance, covariate adjustment, Program evaluation, randomization inference, robust standard errors, sandwich estimator, social experiments},
	pages = {295--318},
	file = {Snapshot:/Users/Justin/Zotero/storage/JERFGF47/1365527200.html:text/html}
}

@article{rosenbaum_covariance_2002,
	title = {Covariance {Adjustment} in {Randomized} {Experiments} and {Observational} {Studies}},
	volume = {17},
	issn = {0883-4237, 2168-8745},
	url = {http://projecteuclid.org/euclid.ss/1042727942},
	doi = {10.1214/ss/1042727942},
	abstract = {By slightly reframing the concept of covariance adjustment in randomized experiments, a method of exact permutation inference is derived that is entirely free of distributional assumptions and uses the random assignment of treatments as the "reasoned basis for inference.'' This method of exact permutation inference may be used with many forms of covariance adjustment, including robust regression and locally weighted smoothers. The method is then generalized to observational studies where treatments were not randomly assigned, so that sensitivity to hidden biases must be examined. Adjustments using an instrumental variable are also discussed. The methods are illustrated using data from two observational studies.},
	number = {3},
	urldate = {2016-10-19},
	journal = {Statistical Science},
	author = {Rosenbaum, Paul R.},
	month = aug,
	year = {2002},
	mrnumber = {MR1962487},
	keywords = {randomization inference, Propensity score, Covariance adjustment, matching, observational studies, permutation inference, Sensitivity analysis},
	pages = {286--327},
	file = {Snapshot:/Users/Justin/Zotero/storage/QIK5BSH4/1042727942.html:text/html}
}

@book{fisher_design_1935,
	address = {Edinburgh},
	title = {The {Design} of {Experiments}},
	publisher = {Oliver \& Boyd},
	author = {Fisher, Ronald Aylmer},
	year = {1935},
	note = {Includes index.
Bibliography: p. 245.},
	keywords = {Experimental design., Statistics.}
}

@techreport{young_channeling_2015,
	title = {Channeling {Fisher}: {Randomization} {Tests} and the {Statistical} {Insignificance} of {Seemingly} {Significant} {Experimental} {Results}},
	shorttitle = {Channeling {Fisher}},
	url = {http://personal.lse.ac.uk/YoungA/ChannellingFisher.pdf},
	urldate = {2016-10-17},
	institution = {Technical Report, Working paper},
	author = {Young, Alwyn},
	year = {2015},
	file = {[PDF] lse.ac.uk:/Users/Justin/Zotero/storage/5WUC7SI4/Young - 2015 - Channeling Fisher Randomization Tests and the Sta.pdf:application/pdf}
}

@article{splawa-neyman_application_1990,
	title = {On the application of probability theory to agricultural experiments. {Essay} on principles. {Section} 9},
	volume = {5},
	url = {http://projecteuclid.org/euclid.ss/1177012031},
	number = {4},
	urldate = {2016-10-17},
	journal = {Statistical Science},
	author = {Splawa-Neyman, Jerzy and Dabrowska, D. M. and Speed, T. P. and {others}},
	year = {1990},
	pages = {465--472},
	file = {Snapshot:/Users/Justin/Zotero/storage/ZGI6UMM6/1177012031.html:text/html}
}

@techreport{abadie_finite_2014,
	type = {Working {Paper}},
	title = {Finite {Population} {Causal} {Standard} {Errors}},
	url = {http://www.nber.org/papers/w20325},
	abstract = {When a researcher estimates the parameters of a regression function using information on all 50 states in the United States, or information on all visits to a website, what is the interpretation of the standard errors? Researchers typically report standard errors that are designed to capture sampling variation, based on viewing the data as a random sample drawn from a large population of interest, even in applications where it is difficult to articulate what that population of interest is and how it differs from the sample. In this paper we explore alternative interpretations for the uncertainty associated with regression estimates. As a leading example we focus on the case where some parameters of the regression function are intended to capture causal effects. We derive standard errors for causal effects using a generalization of randomization inference. Intuitively, these standard errors capture the fact that even if we observe outcomes for all units in the population of interest, there are for each unit missing potential outcomes for the treatment levels the unit was not exposed to. We show that our randomization-based standard errors in general are smaller than the conventional robust standard errors, and provide conditions under which they agree with them. More generally, correct statistical inference requires precise characterizations of the population of interest, the parameters that we aim to estimate within such population, and the sampling process. Estimation of causal parameters is one example where appropriate inferential methods may differ from conventional practice, but there are others.},
	number = {20325},
	urldate = {2016-10-17},
	institution = {National Bureau of Economic Research},
	author = {Abadie, Alberto and Athey, Susan and Imbens, Guido W. and Wooldridge, Jeffrey M.},
	month = jul,
	year = {2014}
}

@article{athey_econometrics_2016,
	title = {The {Econometrics} of {Randomized} {Experiments}},
	url = {http://arxiv.org/abs/1607.00698},
	abstract = {In this review, we present econometric and statistical methods for analyzing randomized experiments. For basic experiments we stress randomization-based inference as opposed to sampling-based inference. In randomization-based inference, uncertainty in estimates arises naturally from the random assignment of the treatments, rather than from hypothesized sampling from a large population. We show how this perspective relates to regression analyses for randomized experiments. We discuss the analyses of stratified, paired, and clustered randomized experiments, and we stress the general efficiency gains from stratification. We also discuss complications in randomized experiments such as non-compliance. In the presence of non-compliance we contrast intention-to-treat analyses with instrumental variables analyses allowing for general treatment effect heterogeneity. We consider in detail estimation and inference for heterogeneous treatment effects in settings with (possibly many) covariates. These methods allow researchers to explore heterogeneity by identifying subpopulations with different treatment effects while maintaining the ability to construct valid confidence intervals. We also discuss optimal assignment to treatment based on covariates in such settings. Finally, we discuss estimation and inference in experiments in settings with interactions between units, both in general network settings and in settings where the population is partitioned into groups with all interactions contained within these groups.},
	urldate = {2016-09-01},
	journal = {arXiv:1607.00698 [stat]},
	author = {Athey, Susan and Imbens, Guido},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.00698},
	keywords = {62K99, G.3, Statistics - Methodology},
	file = {arXiv\:1607.00698 PDF:/Users/Justin/Zotero/storage/VFVDBPGD/Athey and Imbens - 2016 - The Econometrics of Randomized Experiments.pdf:application/pdf;arXiv.org Snapshot:/Users/Justin/Zotero/storage/JKM3NF3U/1607.html:text/html}
}

@article{ligon_estimating_2016,
	title = {Estimating household neediness from disaggregate expenditures},
	url = {http://escholarship.org/uc/item/5gc4h1fm.pdf},
	urldate = {2016-09-21},
	author = {Ligon, Ethan},
	year = {2016}
}